{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Embedding Models in LangChain"
      ],
      "metadata": {
        "id": "br-yEtdhToCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI, HuggingFace and LangChain dependencies"
      ],
      "metadata": {
        "id": "L1KvMtf54l0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.2.0\n",
        "!pip install langchain-openai==0.1.7\n",
        "!pip install langchain-community==0.2.0\n",
        "!pip install langchain-huggingface==0.0.1"
      ],
      "metadata": {
        "id": "2evPp14fy258"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Open AI and HuggingFace API Tokens"
      ],
      "metadata": {
        "id": "H9c37cLnSrbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ],
      "metadata": {
        "id": "cv3JzCEx_PAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "HUGGINGFACEHUB_API_TOKEN = getpass('Enter HuggingFace Auth Token Key: ')"
      ],
      "metadata": {
        "id": "h7vnQZC6_eiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Environment Variables"
      ],
      "metadata": {
        "id": "1T0s0um5Svfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HUGGINGFACEHUB_API_TOKEN"
      ],
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding models\n",
        "\n",
        "The Embeddings class is a class designed for interfacing with text embedding models. There are lots of embedding model providers (OpenAI, Cohere, Hugging Face, etc) - this class is designed to provide a standard interface for all of them.\n",
        "\n",
        "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space.\n",
        "\n",
        "The base Embeddings class in LangChain provides two methods: one for embedding documents and one for embedding a query. The former takes as input multiple texts, while the latter takes a single text. The reason for having these as two separate methods is that some embedding providers have different embedding methods for documents (to be searched over) vs queries (the search query itself)."
      ],
      "metadata": {
        "id": "e81VnNL-Npan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    \"cats eat and sleep\",\n",
        "    \"dogs eat and bark\",\n",
        "    \"cars drive fast\",\n",
        "    \"vehicles include trucks and cars\"\n",
        "]"
      ],
      "metadata": {
        "id": "ZKNTEu9r_6xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space.\n",
        "\n",
        "The base Embeddings class in LangChain provides two methods: one for embedding documents and one for embedding a query. The former, `.embed_documents`, takes as input multiple texts, while the latter, `.embed_query`, takes a single text. The reason for having these as two separate methods is that some embedding providers have different embedding methods for documents (to be searched over) vs queries (the search query itself).\n",
        "\n",
        "- `.embed_query`  will return a list of floats,\n",
        "- `.embed_documents` returns a list of lists of floats."
      ],
      "metadata": {
        "id": "CF4EkcYfNwx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Open AI Embedding Models\n",
        "\n",
        "LangChain enables us to access Open AI embedding models which include the newest models: a smaller and highly efficient `text-embedding-3-small` model, and a larger and more powerful `text-embedding-3-large` model."
      ],
      "metadata": {
        "id": "M8nHAP7XOGOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
        "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
      ],
      "metadata": {
        "id": "jzrIVI2NAHC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = openai_embed_model.embed_documents(docs)"
      ],
      "metadata": {
        "id": "YusSojOAAVAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "id": "93H3jQqlAYza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings[0])"
      ],
      "metadata": {
        "id": "UgC3CyGDAdr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings[0])"
      ],
      "metadata": {
        "id": "GRo0asF4AfBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "dfIZhgRAAkq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "sim_matrix = cosine_similarity(embeddings)\n",
        "sim_matrix"
      ],
      "metadata": {
        "id": "QVffLOp5AlXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Open Source Embedding Models on HuggingFace\n",
        "\n",
        "`langchain-huggingface` integrates seamlessly with LangChain, providing an efficient and effective way to utilize Hugging Face models within the LangChain ecosystem.\n",
        "\n",
        "`HuggingFaceEmbeddings`uses `sentence-transformers` embeddings. It computes the embedding locally, using your computer resources and allows you to access open or open source embedding LLMs hosted on HuggingFace."
      ],
      "metadata": {
        "id": "z1uMrziMOaYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# check out model details here: https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1\n",
        "model_name = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
        "\n",
        "hf_embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        ")"
      ],
      "metadata": {
        "id": "28n79jM-AsBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = hf_embeddings.embed_documents(docs)"
      ],
      "metadata": {
        "id": "UM7xEwiwBXqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "id": "8M20R3q3BfIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings[0])"
      ],
      "metadata": {
        "id": "D_87rUyEBgL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "83qh6lQZVWnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim_matrix = cosine_similarity(embeddings)\n",
        "sim_matrix"
      ],
      "metadata": {
        "id": "zGHEceLfBhB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a small search engine!"
      ],
      "metadata": {
        "id": "3lftCkcFp3cn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Knowledgebase documents"
      ],
      "metadata": {
        "id": "vqhZfWqwO5AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    'Quantum mechanics describes the behavior of very small particles.',\n",
        "    'Photosynthesis is the process by which green plants make food using sunlight.',\n",
        "    \"Shakespeare's plays are a testament to English literature.\",\n",
        "    'Artificial Intelligence aims to create machines that can think and learn.',\n",
        "    'The pyramids of Egypt are historical monuments that have stood for thousands of years.',\n",
        "    'Biology is the study of living organisms and their interactions with the environment.',\n",
        "    'Music therapy can aid in the mental well-being of individuals.',\n",
        "    'The Milky Way is just one of billions of galaxies in the universe.',\n",
        "    'Economic theories help understand the distribution of resources in society.',\n",
        "    'Yoga is an ancient practice that involves physical postures and meditation.'\n",
        "]"
      ],
      "metadata": {
        "id": "LYybmS0Sejd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "id": "pz9HLzPz-YQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get document embeddings"
      ],
      "metadata": {
        "id": "D-llyc6yp-WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_embeddings = openai_embed_model.embed_documents(documents)"
      ],
      "metadata": {
        "id": "9uNIJzSwhSOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's try to find the most similar document for one query"
      ],
      "metadata": {
        "id": "hm9TZcPyqQFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = 'What is AI?'\n",
        "new_text"
      ],
      "metadata": {
        "id": "d1tSZLrnqL-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding = openai_embed_model.embed_query(new_text)"
      ],
      "metadata": {
        "id": "SY684YySMA67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarities = cosine_similarity([query_embedding], document_embeddings)\n",
        "cosine_similarities"
      ],
      "metadata": {
        "id": "9lI1JrtFMDF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "documents[np.argmax(cosine_similarities[0])]"
      ],
      "metadata": {
        "id": "L8ilJpgXMR3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Search Engine function"
      ],
      "metadata": {
        "id": "Q-YNRhmbrnDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_search_engine(query, embedder_model):\n",
        "  query_embedding = embedder_model.embed_query(query)\n",
        "  cos_scores = cosine_similarity([query_embedding], document_embeddings)[0]\n",
        "  top_result_id = np.argmax(cos_scores)\n",
        "  return documents[top_result_id]"
      ],
      "metadata": {
        "id": "d1AEDYNdhfW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try out the function"
      ],
      "metadata": {
        "id": "dvnpjNtervq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentence = 'Tell me about AI'\n",
        "semantic_search_engine(new_sentence, openai_embed_model)"
      ],
      "metadata": {
        "id": "u6waCgoHiSrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentence = 'Do you know about the pyramids?'\n",
        "semantic_search_engine(new_sentence, openai_embed_model)"
      ],
      "metadata": {
        "id": "5fNNYN-lifn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentence = 'How do plants survive?'\n",
        "semantic_search_engine(new_sentence, openai_embed_model)"
      ],
      "metadata": {
        "id": "lod8wnLziqG8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}